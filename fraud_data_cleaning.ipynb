{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client data\n",
    "df_clients =pd.read_csv('data/client_train.csv')\n",
    "\n",
    "# invoice score\n",
    "df_invoice =pd.read_csv('data/invoice_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invoice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invoice[['client_id', 'invoice_date', 'old_index', 'new_index']].query('client_id == \"train_Client_0\"').sort_values(by=['invoice_date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column descriptions:\n",
    "\n",
    "### Client Data\n",
    "\n",
    "* Client_id: Unique id for client\n",
    "* District: District where the client is\n",
    "* Client_catg: Category client belongs to\n",
    "* Region: Area where the client is\n",
    "* Creation_date: Date client joined\n",
    "* Target: fraud:1 , not fraud: 0\n",
    "\n",
    "### Invoice Data\n",
    "\n",
    "* Client_id: Unique id for the client\n",
    "* Invoice_date: Date of the invoice\n",
    "* Tarif_type: Type of tax\n",
    "* Counter_number:\n",
    "* Counter_statue: takes up to 5 values such as working fine, not working, on hold statue, ect\n",
    "* Counter_code:\n",
    "* Reading_remarque: notes that the STEG agent takes during his visit to the client (e.g: If the counter shows something wrong, the agent gives a bad score)\n",
    "* Counter_coefficient: An additional coefficient to be added when standard consumption is exceeded\n",
    "* Consommation_level_1: Consumption_level_1\n",
    "* Consommation_level_2: Consumption_level_2\n",
    "* Consommation_level_3: Consumption_level_3\n",
    "* Consommation_level_4: Consumption_level_4\n",
    "* Old_index: Old index\n",
    "* New_index: New index\n",
    "* Months_number: Month number\n",
    "* Counter_type: Type of counter\n",
    "\n",
    " the consumption level refers to the threshold of consumption to which a certain price is attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = coffee_quality[\"quality_score\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaningin and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invoice.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invoice.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invoice.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined =  pd.merge(df_clients, df_invoice, on=\"client_id\", how=\"left\")\n",
    "#df_clients.join(df_invoice, on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_joined.client_id.nunique())\n",
    "df_joined.counter_number.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.counter_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.client_catg.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.tarif_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.groupby('counter_statue').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.groupby('counter_code').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.counter_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.reading_remarque.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.groupby('reading_remarque').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.counter_coefficient.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.old_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Dos\n",
    "\n",
    "* remove client_id column\n",
    "* turn into dummies: client_catg, tarif_type\n",
    "* change target to 0,1 - DONE\n",
    "* turn creation_date, invoice_date  into datetime or something else - DONE\n",
    "* feature engineering: number of counters per client. then drop client_id, counter_number\n",
    "* counter_statue: turn strings 0-5 into int, check percentage of values not 0-5, check for pattern, remove - DONE\n",
    "* counter_code: either dummies or find info on steg site or drop?\n",
    "* reading_remarque: clean? turn into dummies\n",
    "* counter_coefficient: try both?: treat numerically and as dummies?\n",
    "* rescale consommation_level1 ... _4\n",
    "* drop index old and new\n",
    "* rescale months_number\n",
    "* turn into dummy counter_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many duplicated rows exist in the data frame\n",
    "df_joined.duplicated().value_counts()\n",
    "\n",
    "# there were 11 duplicatge rows, drop duplicates\n",
    "df_joined.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined['counter_statue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter_statue: turn strings 0-5 into int, check percentage of values not 0-5, check for pattern, remove\n",
    "\n",
    "df_joined['counter_statue'] = df_joined['counter_statue'].map({\n",
    "    '0': 0,\n",
    "    0: 0, \n",
    "    1: 1,\n",
    "    2 : 2,\n",
    "    3: 3,\n",
    "    4: 4,  \n",
    "    5: 5,\n",
    "    '5': 5,\n",
    "    '1': 1,\n",
    "    '4': 4, \n",
    "    'A': np.nan,\n",
    "    618: np.nan, \n",
    "    269375: np.nan,\n",
    "    46: np.nan, \n",
    "    420: np.nan,\n",
    "    769: np.nan, \n",
    "    })\n",
    "df_joined['counter_statue'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined['counter_statue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing distribution\n",
    "\n",
    "#msno.matrix(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fraction of data we would lose : 0.001%\n",
    "\n",
    "print(f\"numbers of rows : {df_joined.shape[0]}\")\n",
    "print(f\"missing values in counter statue : {round(df_joined.counter_statue.isna().sum()/df_joined.shape[0]*100,4)} %\")\n",
    "\n",
    "# copy df\n",
    "df_processed = df_joined.copy()\n",
    "# drop NaN\n",
    "df_processed.dropna(inplace=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target from float to int (0,1)\n",
    "df_processed.target = df_processed.target.astype(int)\n",
    "df_processed.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn columns invoice date and creation date to datetime\n",
    "\n",
    "df_processed['invoice_date'] = pd.to_datetime(df_processed['invoice_date'], format='%Y-%m-%d')\n",
    "df_processed['creation_date'] = pd.to_datetime(df_processed['creation_date'], format='%d/%m/%Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df_processed[['disrict', 'client_catg', 'region', 'creation_date',\n",
    "       'target', 'invoice_date', 'tarif_type', 'counter_number',\n",
    "       'counter_statue', 'counter_code', 'reading_remarque',\n",
    "       'counter_coefficient', 'consommation_level_1', 'consommation_level_2',\n",
    "       'consommation_level_3', 'consommation_level_4', 'old_index',\n",
    "       'new_index', 'months_number']].corr(), annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pairplot took a lot of time so we did not see it so far and left it for now\n",
    "\n",
    "# pairplot\n",
    "\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.pairplot(df_processed[['disrict', 'client_catg', 'region', 'creation_date', 'invoice_date', 'tarif_type', 'counter_number',\n",
    "#        'counter_statue', 'counter_code', 'reading_remarque',\n",
    "#        'counter_coefficient', 'consommation_level_1', 'consommation_level_2',\n",
    "#        'consommation_level_3', 'consommation_level_4', 'months_number', 'target']], hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.histplot(data= df_processed, x = 'reading_remarque', hue='target', stat='percent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # since our target has the highest correlation with the client category, we will take a closer look at that: \n",
    "# df_processed.client_catg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot distribution of target for each client category \n",
    "\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.countplot(data= df_processed, x = 'client_catg', hue='target');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot distribution of target for each client category individually, descending by clients in category:\n",
    "\n",
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.histplot(data= df_processed.query('client_catg == 11'), x = 'client_catg', hue='target', stat='percent');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.histplot(data= df_processed.query('client_catg == 51'), x = 'client_catg', hue='target', stat='percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.histplot(data= df_processed.query('client_catg == 12'), x = 'client_catg', hue='target', stat='percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the highest amount of fraud happens by clients assigned to category 51, \n",
    "# so our very fist guess for a hypothesis and baseline mode could be:\n",
    "# client category is the best predictor for fraud\n",
    "# however, due tue the unbalanced data, this would be a very poor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "* run baseline model and print the different scores for it\n",
    "* Drop old and new index\n",
    "* Train-Test-Split\n",
    "* Define Target y, and Features X\n",
    "* Feature Engineering\n",
    "* Dummy Creating\n",
    "* Rescaling based on train, apply to test\n",
    "* dropping other unused columns\n",
    "* export X-test, X_train, y_test and y_train to a new notebook for modeling (find library to help us with that)\n",
    "* individual modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # month and year from date columns\n",
    "# df_processed['creation_month'] = df_processed['creation_date'].dt.month.astype(int)\n",
    "# df_processed['creation_year'] = df_processed['creation_date'].dt.year.astype(int)\n",
    "# df_processed['invoice_month'] = df_processed['invoice_date'].dt.month.astype(int)\n",
    "# df_processed['invoice_year'] = df_processed['invoice_date'].dt.year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of years as client\n",
    "\n",
    "df_processed['member_years'] = df_processed['invoice_date'].dt.year.astype(int) - df_processed['creation_date'].dt.year.astype(int)\n",
    "df_processed.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop creation_date and invoice_date\n",
    "df_processed.drop(['creation_date','invoice_date'] , inplace=True,axis=1)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarif type valuecount\n",
    "\n",
    "df_processed['tarif_type'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin tariff\n",
    "\n",
    "\n",
    "df_processed['tarif_type'] = df_processed['tarif_type'].map({\n",
    "    \n",
    "    11 : 11,\n",
    "    40 : 40,\n",
    "    10 : 10,\n",
    "    15  : 15,\n",
    "    45   : 45,\n",
    "    13  : 13,\n",
    "    14  : 14,\n",
    "    12  : 12,\n",
    "    29  : 29,\n",
    "    9  : 0,\n",
    "    21  :0,\n",
    "    8   : 0,\n",
    "    30  : 0,\n",
    "    24  : 0,\n",
    "    18   : 0,\n",
    "    42  : 0,\n",
    "    27  :0\n",
    "    \n",
    "    })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new feature index_change\n",
    "df_processed['index_change']= df_processed['new_index'] - df_processed['old_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.query('months_number == 0').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.query('client_id == \"train_Client_86638\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete client with 0 consommation, 0 months_number...\n",
    "df_processed.drop(index=3985967 , inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.query('months_number == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index change per month\n",
    "\n",
    "\n",
    "df_processed['index_change_month']= df_processed['index_change'] / df_processed['months_number']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all  columns \n",
    "# Consummation_level_1 through 4, district, invoice_date, creation_date, counter_coefficient, index_change, months_number\n",
    "\n",
    "df_processed.drop(['consommation_level_1', 'consommation_level_2', 'consommation_level_3', 'consommation_level_4',\n",
    "                'disrict',  'counter_coefficient', 'index_change', 'months_number', 'counter_code'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(20,10))\n",
    "#sns.histplot(data=df_processed, x='index_change' ,hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['index_change_month'].corr(df_processed['target']) #  correlation is very low "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[['index_change_month']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.drop(['old_index','new_index'] , inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter per client feature\n",
    "quantity_counter = df_processed.groupby('client_id')['counter_number'].count().reset_index()\n",
    "quantity_counter.rename(columns={'counter_number':'quantity_counters'}, inplace=True)\n",
    "quantity_counter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.merge(df_processed, quantity_counter, on=\"client_id\", how=\"left\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['quantity_counters'].corr(df_processed['target']) #  correlation is very low "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,10))\n",
    "# sns.histplot(df_processed, x='quantity_counters', hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop client_id and counter_number\n",
    "df_processed.drop(['client_id','counter_number'] , inplace=True,axis=1)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename district column\n",
    "df_processed.rename(columns={'disrict':'district'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap with the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df_processed[['client_catg', 'region', 'target', 'tarif_type', 'counter_statue',\n",
    "       'reading_remarque',  'member_years',\n",
    "       'index_change_month', 'quantity_counters']].corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Categorical Features into Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['client_catg',\n",
    " 'region',\n",
    " 'tarif_type',\n",
    " 'counter_statue',\n",
    " 'reading_remarque',\n",
    " 'counter_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [x for x in df_processed.columns.to_list() if x not in cat_features]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove target\n",
    "num_features.remove(\"target\")\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables from categorical features, dtype int\n",
    "dummies = pd.get_dummies(df_processed[cat_features], columns=cat_features, drop_first=True, dtype=int)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy variables to dataframe with dropped categorical columns\n",
    "df_processed_dmy =  pd.concat([df_processed.drop(cat_features,axis=1), dummies],axis=1)\n",
    "df_processed_dmy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_dmy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the preprocessed dataframe\n",
    "df_processed_dmy.to_csv('data/df_processed_dmy.csv', index=False)\n",
    "\n",
    "# # add to new notebooks:\n",
    "# # load the preprocessed dataframe\n",
    "# %store -r df_processed_dmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Categorical Features into Dummys for Tree-Models (no drop-first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables from categorical features, dtype int, without dropping the first dummy columns\n",
    "dummies_tree = pd.get_dummies(df_processed[cat_features], columns=cat_features, drop_first=False, dtype=int)\n",
    "dummies_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy variables to dataframe with dropped categorical columns\n",
    "df_processed_dmy_tree =  pd.concat([df_processed.drop(cat_features,axis=1), dummies_tree],axis=1)\n",
    "df_processed_dmy_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the preprocessed dataframe for tree models\n",
    "df_processed_dmy_tree.to_csv('data/df_processed_dmy_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Dos\n",
    "\n",
    "* counter_code: find info on steg site or drop?\n",
    "* reading_remarque: clean? \n",
    "* counter_coefficient: try both?: treat numerically and as dummies?\n",
    "* rescale consommation_level1 ... _4\n",
    "* rescale months_number\n",
    "\n",
    "## Done\n",
    "* rename 'disrict' column 'district'\n",
    "* turn creation_date, invoice_date  into datetime\n",
    "* change target to 0,1\n",
    "* counter_statue: turn strings 0-5 into int, check percentage of values not 0-5, check for pattern, remove\n",
    "* feature engineering: index_change = new_idex - old_index. then drop new_index, old_index\n",
    "* feature engineering: number of counters per client. then drop client_id, counter_number\n",
    "* turn into dummies: cat_features = ['district', 'client_catg', 'region', 'tarif_type', 'counter_statue', 'counter_code', 'reading_remarque', 'counter_coefficient', 'counter_type']\n",
    "* export processed dataframe\n",
    "* turn date columns into months and year columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save current version of processed data for use later\n",
    "\n",
    "#df_processed.to_csv('data/fraud_data_processed_V1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store num-features\n",
    "%store num_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
