{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours (KNN) for Fraud Detection\n",
    "\n",
    "---\n",
    "\n",
    "* KNN, Supervised learning algorithm:\n",
    "  - assumption: similar inputs have similar outputs\n",
    "  - high similarity implies same class label\n",
    "\n",
    "* Algorithm:\n",
    "  - train set\n",
    "  - distance function to calculate similarity : Euclidean , Mahalanobis\n",
    "  - Hyperparameter, K\n",
    "  - Find k-closest points to new point \n",
    "  - Decision strategy : Mode or weighted distances?\n",
    "  - Assign new point to fraud or no fraud based on strategy\n",
    "\n",
    "* Choosing K:\n",
    "  - can use cross-validation, elbow method?\n",
    "\n",
    "* Improving KNN\n",
    "  - change the metric distance\n",
    "  - dimensionality reduction\n",
    "  - rescaling and normalization\n",
    "  - modified approach\n",
    "\n",
    "* Visualization of the likelihood a new test point belongs to a class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Import libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, fbeta_score, make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV,  GridSearchCV\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "\n",
    "# import custom functions\n",
    "\n",
    "from custom_functions import get_data_summary, our_metrics, eval_metrics, evaluate_model\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Load necessary processed data\n",
    "\n",
    "---\n",
    "\n",
    "* Unscaled Data (test_size = 0.25) :\n",
    "  - X_train.csv\n",
    "  - X_test.csv\n",
    "  - y_train.csv\n",
    "  - y_test.csv\n",
    "\n",
    "* Scaled Data - minmax scaler (normalization) :\n",
    "  - X_train_std.csv\n",
    "  - X_test_std.csv\n",
    "\n",
    "* Scaled Data - standard scaler (standardization) :\n",
    "  - X_train_minmax.csv\n",
    "  - X_test_minmax.csv\n",
    "\n",
    "* minmax scaled with x_train_minmax and y_train split using test_size = 0.7 :\n",
    "  - X_train_minmax_small.csv (train?)\n",
    "  - y_train_minmax_small.csv (train)\n",
    "  - X_train_minmax_large.csv (still train? since scaled)\n",
    "  - y_train_minmax_large.csv (test)\n",
    "\n",
    "* standard scaler with x_train_std and y_train split using test_size = 0.7 :\n",
    "  - X_train_std_small.csv (train?)\n",
    "  - y_train_std_small.csv (train)\n",
    "  - X_train_std_large.csv (now test)\n",
    "  - y_train_std_large.csv (test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the data files\n",
    "\n",
    "\n",
    "# unscaled Data (test_size = 0.25) :\n",
    "\n",
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "\n",
    "# scaled Data - minmax scaler\n",
    "\n",
    "X_train_std = pd.read_csv(\"data/X_train_std.csv\")\n",
    "X_test_std  = pd.read_csv(\"data/X_test_std.csv\")\n",
    "\n",
    "# scaled Data - standard scaler\n",
    "\n",
    "X_train_minmax  = pd.read_csv(\"data/X_train_minmax.csv\")\n",
    "X_test_minmax  = pd.read_csv(\"data/X_test_minmax.csv\")\n",
    "\n",
    "# minmax scaled with x_train_minmax and y_train split using test_size = 0.7\n",
    "\n",
    "X_train_minmax_small  = pd.read_csv(\"data/X_train_minmax_small.csv\")\n",
    "X_train_minmax_large  = pd.read_csv(\"data/X_train_minmax_large.csv\")\n",
    "\n",
    "# standard scaler with x_train_std and y_train split using test_size = 0.7\n",
    "\n",
    "X_train_std_small  = pd.read_csv(\"data/X_train_std_small.csv\")\n",
    "X_train_std_large  = pd.read_csv(\"data/X_train_std_large.csv\")\n",
    "\n",
    "y_train_small  = pd.read_csv(\"data/y_train_small.csv\")\n",
    "y_train_large  = pd.read_csv(\"data/y_train_large.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape data files\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train : {X_train.shape}\")\n",
    "print(f\" X_test :{X_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" y_train : {y_train.shape}\")\n",
    "print(f\" y_test : {y_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_std : {X_train_std.shape}\")\n",
    "print(f\" X_test_std : {X_test_std.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_minmax : {X_train_minmax.shape}\")\n",
    "print(f\" X_test_minmax : {X_test_minmax.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_minmax_small : {X_train_minmax_small.shape}\")\n",
    "print(f\" X_train_minmax_large : {X_train_minmax_large.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_std_small : {X_train_std_small.shape}\")\n",
    "print(f\" X_train_std_large : {X_train_std_large.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" y_train_small : {y_train_small.shape}\")\n",
    "print(f\" y_train_large : {y_train_large.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Global Variables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# for reproducibility sake\n",
    "RSEED = 42\n",
    "\n",
    "# test values for the n_neighbors parameter for unscaled X_train\n",
    "params_0 = {\n",
    "            'n_neighbors' : [50, 100, 500, len(X_train//16),\n",
    "                len(X_train//8), len(X_train//4),  len(X_train//2)],   \n",
    "        }\n",
    "\n",
    "Threshold = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Distance measure\n",
    "\n",
    "---\n",
    "\n",
    "metric = DistanceMetric.get_metric('mahalanobis', V=np.cov(train_features))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# K-neighbours classifier \n",
    "\n",
    "---\n",
    "\n",
    "* initialize model\n",
    "* cross validation to find optima K : random search , grid search\n",
    "* fit model \n",
    "* parameters used :\n",
    "<br> <br/>\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "cv_params = [\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['euclidean', 'minkowski']},\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['mahalanobis', 'seuclidean'],\n",
    "     'metric_params': [{'V': np.cov(train_input_data)}]}\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Dimensionality reduction :\n",
    "\n",
    "* how to solve th curse of dimensionality problem\n",
    "* Using principal component analysis (PCA)\n",
    "    - if data has multi-colinearity between the features or variables\n",
    "    - if the input data is high dimensional (lots feature variables)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4000\n",
    "\n",
    "n_x_train = X_train[:n_samples]\n",
    "n_y_train = y_train[:n_samples]\n",
    "n_x_test = X_test[:n_samples]\n",
    "n_y_test = y_test[:n_samples]\n",
    "\n",
    "print(f\" n samples from x_train : {n_x_train.shape}\")\n",
    "print(f\" n samples from y_train : {n_y_train.shape}\")\n",
    "\n",
    "print(\"_____\"*25)\n",
    "\n",
    "print(f\" n samples from x_test : {n_x_test.shape}\")\n",
    "print(f\"  n samples from y_test : {n_y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scorer names\n",
    "# import sklearn.metrics as sm\n",
    "# sm.get_scorer_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## results of grid search run previously\n",
    "\n",
    "_____________________________________________________________________________________________________________________________\n",
    "_____________________________________________________________________________________________________________________________\n",
    "best K grid search: 60\n",
    "best metric grid search: mahalanobis\n",
    "_____________________________________________________________________________________________________________________________\n",
    "optimal parameters, score, algorithm\n",
    "\n",
    "        \n",
    "_____________________________________________________________________________________________________________________________\n",
    "best score gridcv : 0.5740317387792053\n",
    "_____________________________________________________________________________________________________________________________\n",
    "best params gridcv : {'algorithm': 'auto', 'metric': 'mahalanobis', 'metric_params': {'VI': array([[ 162.91281221,  134.91084644,  110.33487512, ...,   99.82215541,\n",
    "         376.41258094,   19.60800185],\n",
    "       [ 134.91084644,  243.40304117,   95.24653099, ...,  137.64743293,\n",
    "         477.60430157,  115.94993062],\n",
    "       [ 110.33487512,   95.24653099,   78.61170213, ...,   71.97548566,\n",
    "         259.30018501,   14.363321  ],\n",
    "       ...,\n",
    "       [  99.82215541,  137.64743293,   71.97548566, ...,   86.23751156,\n",
    "         299.49213691,   52.31429232],\n",
    "       [ 376.41258094,  477.60430157,  259.30018501, ...,  299.49213691,\n",
    "        1078.95559667,  171.19426457],\n",
    "       [  19.60800185,  115.94993062,   14.363321  , ...,   52.31429232,\n",
    "         171.19426457,   78.85661425]])}, 'n_neighbors': 60, 'weights': 'uniform'}\n",
    "_____________________________________________________________________________________________________________________________\n",
    "best estimator gridcv : KNeighborsClassifier(metric='mahalanobis',\n",
    "                     metric_params={'VI': array([[ 162.91281221,  134.91084644,  110.33487512, ...,   99.82215541,\n",
    "         376.41258094,   19.60800185],\n",
    "       [ 134.91084644,  243.40304117,   95.24653099, ...,  137.64743293,\n",
    "         477.60430157,  115.94993062],\n",
    "       [ 110.33487512,   95.24653099,   78.61170213, ...,   71.97548566,\n",
    "         259.30018501,   14.363321  ],\n",
    "       ...,\n",
    "       [  99.82215541,  137.64743293,   71.97548566, ...,   86.23751156,\n",
    "         299.49213691,   52.31429232],\n",
    "       [ 376.41258094,  477.60430157,  259.30018501, ...,  299.49213691,\n",
    "        1078.95559667,  171.19426457],\n",
    "       [  19.60800185,  115.94993062,   14.363321  , ...,   52.31429232,\n",
    "         171.19426457,   78.85661425]])},\n",
    "                     n_neighbors=60)\n",
    "___________________________________________\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape \n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_test : {X_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" y_train: {y_train.shape}\")\n",
    "print(f\" y_test : {y_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_std : {X_train_std.shape}\")\n",
    "print(f\" X_test_std : {X_test_std.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split on\n",
    "# - X_train_tree_small,  y_train_tree_small\n",
    "\n",
    "\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_train_std, y_train, test_size=0.997, random_state=RSEED, stratify=y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(f\" y_train_knn: {y_train_knn.shape}\")\n",
    "print(f\" y_test_knn : {y_test_knn.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_knn : {X_train_knn.shape}\")\n",
    "print(f\" X_test_knn : {X_test_knn.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation : random search\n",
    "\n",
    "cv_params_1 = [\n",
    "    {'n_neighbors': np.arange(15, 61), 'metric': ['euclidean', 'manhattan', 'cosine']},\n",
    "    # {'n_neighbors': np.arange(1, 51), 'metric': ['mahalanobis', 'seuclidean'],\n",
    "    # 'metric_params': [{'V': np.cov(n10k_x_train)}]},\n",
    "    {'n_neighbors': np.arange(15, 61), \n",
    "    'metric': ['mahalanobis'],\n",
    "    'metric_params': [{'VI': np.cov(X_train_knn)}],\n",
    "    'algorithm' : ['auto', 'brute', 'kd_tree', 'ball_tree'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# scoring = ['fbeta_score', 'f1_score', 'roc_auc_score', 'balanced_accuracy_score']\n",
    "# scoring = ['roc_auc', 'f1_weighted', 'balanced_accuracy']\n",
    "\n",
    "knn_cv_test_1 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rs_1 = RandomizedSearchCV(knn_cv_test_1, cv_params_1, \n",
    "                                scoring = 'roc_auc', \n",
    "                                cv= 5, verbose= 0, n_iter= 20, n_jobs = -1, \n",
    "                                return_train_score= True, random_state= RSEED ) #, refit= False)\n",
    "\n",
    "\n",
    "print(\"_____\"*25)\n",
    "print(\"_____\"*25)\n",
    "\n",
    "# fit model with best param\n",
    "knn_cv_rs_1.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "print(\"_____\"*25)\n",
    "print(\"_____\"*25)\n",
    "\n",
    "\n",
    "# get optimal K hyperparameter and metric\n",
    "\n",
    "best_k_1 = knn_cv_rs_1.best_params_.get('n_neighbors')\n",
    "best_metric_1 = knn_cv_rs_1.best_params_.get('metric')\n",
    "\n",
    "print(\"_____\"*25)\n",
    "\n",
    "print(f\"best K random search: {best_k_1}\")\n",
    "print(f\"best metric random search: {best_metric_1}\")\n",
    "\n",
    "print(\"_____\"*25)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "\n",
    "knn_cv_rsp1 = pd.DataFrame(knn_cv_rs_1.cv_results_['params']).drop('metric_params', axis=1)\n",
    "knn_cv_rsp1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all results the KNN cv\n",
    "\n",
    "knn_cv_rspo = pd.DataFrame(knn_cv_rs_1.cv_results_)[['mean_train_score', 'mean_test_score',  'rank_test_score']]\n",
    "\n",
    "\n",
    "knn_cv_results_1 = pd.concat([knn_cv_rsp1, knn_cv_rspo], axis=1)\n",
    "\n",
    "knn_cv_results_1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print out best parameters, scoresa and estimator (algorithm)\n",
    "\n",
    "\n",
    "print(f'''optimal parameters, score, algorithm\n",
    "\n",
    "        ''')\n",
    "\n",
    "print(\"_____\"*25)\n",
    "\n",
    "\n",
    "# knn_cv_grid_1.get_params()\n",
    "# knn_cv_grid_1.cv_results_\n",
    "\n",
    "print(f\"best score randomcv : {knn_cv_rs_1.best_score_}\")\n",
    "print(\"_____\"*25)\n",
    "\n",
    "print(f\"best params randomcv : {knn_cv_rs_1.best_params_}\")\n",
    "print(\"_____\"*25)\n",
    "\n",
    "print(f\"best estimator randomcv : {knn_cv_rs_1.best_estimator_}\")\n",
    "print(\"_____\"*25)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# draft fit on X_train\n",
    "\n",
    "best_k_rs = 47\n",
    "\n",
    "knn_rs_cos = KNeighborsClassifier(metric='cosine', n_neighbors=best_k_rs)\n",
    "knn_rs_cos.fit(X_train_knn, y_train_knn)\n",
    "knn_rs_cos.score(X_test_knn, y_test_knn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "#knn_pca.get_params().keys()\n",
    "\n",
    "knn_rs_cos.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities knn random search on standardized large X test\n",
    "\n",
    "x_test_knnrs_probs = knn_rs_cos.predict_proba(X_test_knn)\n",
    "x_test_knnrs_probs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities knn random search on originally unscaled X_test\n",
    "\n",
    "x_train_knnrs_probs = knn_rs_cos.predict_proba(X_train_knn)\n",
    "x_train_knnrs_probs \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "y_pred_knnrs_train = knn_rs_cos.predict(X_train_knn)\n",
    "y_pred_knnrs_test = knn_rs_cos.predict(X_test_knn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cleaned data used in modelling notebook\n",
    "\n",
    "df_processed = pd.read_csv('data/df_processed_dmy.csv')\n",
    "\n",
    "\n",
    "## Defining baseline model that predicts no one commits fraud\n",
    "def baseline_model(df):\n",
    "    y_pred = [0 for x in df.index]\n",
    "    return y_pred\n",
    "\n",
    "# Compute predictions with baseline model  1 for test set\n",
    "\n",
    "y_pred_baseline_1 = baseline_model(X_test)\n",
    "\n",
    "\n",
    "# Defining baseline model that predicts no one commits fraud for \n",
    "#  index change with respect to consuption per month <= 15% is fraud\n",
    "\n",
    "\n",
    "quantile_idx = df_processed[['index_change_month']].quantile(q=0.15)[0]\n",
    "quantile_idx\n",
    "\n",
    "def baseline_model_idx(df, quantile_idx):\n",
    "    y_pred = [1 if x <= quantile_idx else 0 for x in df['index_change_month']]\n",
    "    return y_pred\n",
    "\n",
    "# Compute predictions with baseline modelv2 for test set\n",
    "y_pred_baseline_2 = baseline_model_idx(X_test, quantile_idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# our metrics : evaluation and results\n",
    "# - Train\n",
    "# - Test\n",
    "# - Baseline 1\n",
    "# - Baseline 2\n",
    "\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train_knn, y_pred_knnrs_train)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test_knn, y_pred_knnrs_test)}')\n",
    "print(f'Baseline 1 ROC AUC Score: {roc_auc_score(y_test,  y_pred_baseline_1)}')\n",
    "print(f'Baseline 2 ROC AUC Score: {roc_auc_score(y_test, y_pred_baseline_2)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# our metrics : evaluation and results\n",
    "# - Train\n",
    "\n",
    "print(f'Train metrics:  \\n  {our_metrics(y_train_knn, y_pred_knnrs_train)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Test\n",
    "\n",
    "print(f'Test metrics:  \\n  {our_metrics(y_test_knn, y_pred_knnrs_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Baseline 1\n",
    "print(f'Baseline 1 Metrics:  \\n {our_metrics(y_test, y_pred_baseline_1)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Baseline 2\n",
    "\n",
    "print(f'Baseline 2 Metrics: \\n {our_metrics(y_test, y_pred_baseline_2)}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities on labels as well to make them comparable \n",
    "\n",
    "y_train_pred_probs = knn_rs_cos.predict_proba(y_train_knn)[:, 1]\n",
    "y_test_pred_probs = knn_rs_cos.predict_proba(y_test_knn)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_test : {X_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" y_train: {y_train.shape}\")\n",
    "print(f\" y_test : {y_test.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_std : {X_train_std.shape}\")\n",
    "print(f\" X_test_std : {X_test_std.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" y_train: {y_train_knn.shape}\")\n",
    "print(f\" y_test : {y_test_knn.shape}\")\n",
    "\n",
    "print('____'*12)\n",
    "\n",
    "print(f\" X_train_std : {X_train_knn.shape}\")\n",
    "print(f\" X_test_std : {X_test_knn.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca=PCA(0.95)\n",
    "pca=PCA()\n",
    "\n",
    "x_train_pca = pca.fit_transform(reduced_x_train)\n",
    "x_train_pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "\n",
    "x_size = x_train_pca.shape\n",
    "\n",
    "# get number of components\n",
    "\n",
    "ncomp = pca.n_components_\n",
    "\n",
    "print(f\"x train pca size : {x_size}\")\n",
    "print(f\"no of components : {ncomp}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pca = pca.transform(reduced_x_test)\n",
    "x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "\n",
    "xt_size = x_test_pca.shape\n",
    "\n",
    "# get number of components\n",
    "\n",
    "tncomp = pca.n_components_\n",
    "\n",
    "print(f\"x test pca size : {xt_size}\")\n",
    "print(f\"no of components : {tncomp}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# draft fit on X_train\n",
    "\n",
    "\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=48)\n",
    "knn_pca.fit(x_train_pca, reduced_y_train)\n",
    "knn_pca.score(x_test_pca, reduced_y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "#knn_pca.get_params().keys()\n",
    "\n",
    "knn_pca.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities pca\n",
    "\n",
    "x_test_pca_probs = knn_pca.predict_proba(x_test_pca)\n",
    "x_test_pca_probs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities Xtest with no of observations = \n",
    "\n",
    "x_test_probs = knn_pca.predict_proba(X_test)\n",
    "x_test_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold on X_test\n",
    "Threshold = 0.5\n",
    "\n",
    "preds_probs_pca = np.where(x_test_probs[:,1] > Threshold, 1, 0)\n",
    "preds_probs_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "pred_pca = knn_pca.predict(x_test_pca)\n",
    "\n",
    "\n",
    "# evaluation metrics : Fbeta_score with bete = [1.5, 2, 3]\n",
    "# confusion matrix \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn = 48\n",
    "best_metric = 'mahaladonis'\n",
    "scorers = \n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=best_nn)\n",
    "\n",
    "legend = {}\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-35, 35, 500), np.linspace(-35, 35, 500))\n",
    "plt.figure(1, figsize=(10,10))\n",
    "\n",
    "\n",
    "knn_clf.fit(X_train_knn.values[:,:2])\n",
    "\n",
    "Z = knn_clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "legend['K-Nearest Neighbors'] = plt.contour(\n",
    "    xx, yy, Z, levels=[0], linewidths=2, colors=['m'])\n",
    "\n",
    "legend_values_list = list(legend.values())\n",
    "legend_keys_list = list(legend.keys())\n",
    "\n",
    "plt.figure(1, figsize=(10,10))# two clusters\n",
    "plt.title(\"Outlier detection on first two columns of Fraud data\")\n",
    "\n",
    "plt.scatter(X_train_knn.values[:, 0], X_train_knn.values[:, 1], color='black')\n",
    "\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "\n",
    "plt.xlim((xx.min(), xx.max()))\n",
    "plt.ylim((yy.min(), yy.max()))\n",
    "\n",
    "plt.legend(legend_values_list[0].collections, legend_keys_list,\n",
    "           loc=\"upper center\");\n",
    "plt.ylabel(\"feature1\");\n",
    "plt.xlabel(\"feature0\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our metric : fbeta_score\n",
    "\n",
    "fb_score = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "fb_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow method to determine best K value\n",
    "# 'n_neighbors': np.arange(50,len(X_train//2) + 1), \n",
    "# 'metric': 'mahalanobis'\n",
    "# 'metric_params': [{'V': np.cov(X_train)]\n",
    "\n",
    "k_range = range(5, 50)\n",
    "#hyperparameters = {\n",
    "#                \"n_neighbors\" : \n",
    "#    }\n",
    "\n",
    "score_kis = []\n",
    "\n",
    "for i in k_range:\n",
    "    knn_0 = KNeighborsClassifier(n_neighbors=i, \n",
    "                                metric= 'euclidean') #'mahalanobis', metric_params=[{'V': np.cov(reduced_x_train)}])\n",
    "    \n",
    "    \n",
    "    knn_0.fit(reduced_x_train, reduced_y_train)\n",
    "    score_kis.append(knn_0.best_params_.get('n_neighbors'))\n",
    "\n",
    "\n",
    "# fig=plt.figure(figsize=(10,6))  \n",
    "# fig.patch.set_facecolor('#f6f5f5')\n",
    "\n",
    "# plt.plot(k_range, wcss)\n",
    "# plt.title('The Elbow Method', fontsize = 20)\n",
    "# plt.xlabel('No. of K- neighbours')\n",
    "# plt.ylabel('wcss')\n",
    "# fig.text(0.5,0.4,\"The best k-value is here\")\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### K-NN on regular split : X_train and y_train\n",
    "\n",
    "* initialize and fit model on original split data\n",
    "* X_train, y_train\n",
    "\n",
    "* parameters used :\n",
    "<br> <br/>\n",
    "\n",
    "```python\n",
    "\n",
    "cv_params = [\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['euclidean', 'minkowski']},\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['mahalanobis', 'seuclidean'],\n",
    "     'metric_params': [{'V': np.cov(X_train)}]}\n",
    "]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize and fit model \n",
    "# - X_train, y_train data\n",
    "\n",
    "\n",
    "knn_orig = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_orig.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize, cross validation and fit model \n",
    "# - X_train, y_train data\n",
    "\n",
    "\n",
    "grid_params_1 = [\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['euclidean', 'minkowski']},\n",
    "    {'n_neighbors': np.arange(1, 51), 'metric': ['mahalanobis', 'seuclidean'],\n",
    "     'metric_params': [{'V': np.cov(X_train)}]}\n",
    "]\n",
    "\n",
    "knn_orig = knn_cv_fit(X_train, y_train, cv_params = {'n_neighbors' : 5, 'metric':'euclidean'}, cv_type = 'random')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict on test\n",
    "\n",
    "y_pred_orig = knn_orig.predict(X_test)\n",
    "\n",
    "# Make probability predictions\n",
    "train_probs_knn_orig = knn_orig.predict_proba(X_train)[:, 1]\n",
    "test_probs_knn_orig = knn_orig.predict_proba(X_test_minmax)[:, 1]\n",
    "\n",
    "train_preds_knn_orig = knn_orig.predict(X_train)\n",
    "test_preds_knn_orig = knn_orig.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation and results\n",
    "\n",
    "\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs_knn_orig)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test, test_probs_knn_orig)}')\n",
    "print(f'Baseline ROC AUC: {roc_auc_score(y_test, [1 for _ in range(len(y_test))])}')\n",
    "\n",
    "print(eval_metrics(y_test, y_pred_orig))\n",
    "print(evaluate_model(test_preds_knn_orig, test_probs_knn_orig, train_preds_knn_orig,\n",
    "                    train_probs_knn_orig))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-NN on standardized data : test_size = 0.7, large\n",
    "\n",
    "* initialize and fit model on original split data\n",
    "* X_train_std_large, y_train\n",
    "* cross validation : random search then grid search, cv = 5\n",
    "\n",
    "* parameters used :\n",
    "<br> <br/>\n",
    "\n",
    "```python\n",
    "params_1 = {\n",
    "            'n_neighbors' : [5, 100, 500, len(x_train//16),\n",
    "                len(x_train//8), len(x_train//4),  len(x_train//2)],\n",
    "            'metric': ['euclidean', 'mahalanobis'] \n",
    "               }\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# on X_train_std_large, X_test_std\n",
    "\n",
    "# initialize and fit/train model on data\n",
    "\n",
    "knn_std_large = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_std_large.fit(X_train_std_large, y_train)\n",
    "\n",
    "# predict on test\n",
    "\n",
    "y_pred_std = knn_std_large.predict(X_test_std)\n",
    "\n",
    "# Make probability predictions\n",
    "train_probs_knn_stdl = knn_std_large.predict_proba(X_train_std_large)[:, 1]\n",
    "test_probs_knn_stdl = knn_std_large.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "train_preds_knn_stdl = knn_std.predict(X_train_std_large)\n",
    "test_preds_knn_stdl = knn_std.predict(X_test_std)\n",
    "\n",
    "\n",
    "# evaluation and results\n",
    "\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train_large, train_probs_knn_stdl)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test, test_probs_knn_stdl)}')\n",
    "print(f'Baseline ROC AUC: {roc_auc_score(y_test, [1 for _ in range(len(y_test))])}')\n",
    "\n",
    "print(eval_metrics(y_test, y_pred_std))\n",
    "print(evaluate_model(test_preds_knn_stdl, test_probs_knn_stdl, \n",
    "                    train_preds_knn_stdl, train_probs_knn_stdl))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of KNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
